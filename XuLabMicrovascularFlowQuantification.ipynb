{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381484a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do a super resolution with ESRGAN\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ProSR import ProSR\n",
    "\n",
    "# Load the ProSR model\n",
    "model = ProSR()\n",
    "\n",
    "# Open the low resolution video\n",
    "cap = cv2.VideoCapture(\"low_resolution_video.avi\")\n",
    "\n",
    "# Get the video dimensions\n",
    "width = int(cap.get(3))\n",
    "height = int(cap.get(4))\n",
    "\n",
    "# Define the codec and create a video writer object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter('high_resolution_video.avi',fourcc, 30.0, (width*4, height*4))\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if ret==True:\n",
    "        # Perform super-resolution on the frame\n",
    "        sr_frame = model.predict(frame, scale=4)\n",
    "\n",
    "        # Write the high resolution frame to the output video\n",
    "        out.write(sr_frame)\n",
    "\n",
    "        # Display the frame\n",
    "        cv2.imshow('frame',sr_frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# Release the video writer and capture objects\n",
    "cap.release()\n",
    "out.release()\n",
    "\n",
    "# Close all windows\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce0fbc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b993b363",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#COLORIZATION\n",
    "from skimage.io import imread, imshow\n",
    "from skimage.color import rgb2hsv\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from skimage import filters\n",
    "import skimage\n",
    "from PIL import Image\n",
    "import os\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "video = cv2.VideoCapture(r\"C:\\Users\\tzhou\\Downloads\\50x50 micrometer channel D 0.075ul per min 40x with dextran 02(1).mp4\")\n",
    "\n",
    "i = 0\n",
    "while(1):\n",
    "    success, bags = video.read()\n",
    "    cv2.imwrite(\"image\"+str(i)+\"GRAY.png\", bags)\n",
    "    lab = cv2.cvtColor(bags, cv2.COLOR_BGR2LAB)\n",
    "    l_channel, a, b = cv2.split(lab)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    cl = clahe.apply(l_channel)\n",
    "    limg = cv2.merge((cl,a,b))\n",
    "    enhanced_img = cv2.cvtColor(limg, cv2.COLOR_LAB2BGR)\n",
    "\n",
    "\n",
    "    bags_hsv = enhanced_img\n",
    "   \n",
    "    \n",
    "\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(12,4))\n",
    "    ax[0].imshow(bags_hsv[:,:,0], cmap='gray')\n",
    "    ax[0].set_title('Hue')\n",
    "    ax[1].imshow(bags_hsv[:,:,1], cmap='gray')\n",
    "    ax[1].set_title('Saturation')\n",
    "    ax[2].imshow(bags_hsv[:,:,2], cmap='gray')\n",
    "    ax[2].set_title('Value');\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(15, 5))\n",
    "    ax[0].imshow(bags_hsv[:,:,0],cmap='hsv')\n",
    "    ax[0].set_title('hue')\n",
    "    ax[1].imshow(bags_hsv[:,:,1],cmap='hsv')\n",
    "    ax[1].set_title('transparency')\n",
    "    ax[2].imshow(bags_hsv[:,:,2],cmap='hsv')\n",
    "    ax[2].set_title('value')\n",
    "    fig.colorbar(imshow(bags_hsv[:,:,0],cmap='hsv'))\n",
    "    fig.tight_layout()\n",
    "\n",
    "    # refer to hue channel (in the colorbar)\n",
    "    lower_mask = bags_hsv[:, :, 0] > 110\n",
    "\n",
    "    # refer to hue channel (in the colorbar)\n",
    "    upper_mask = bags_hsv[:, :, 0] < 140\n",
    "\n",
    "    # refer to transparency channel (in the colorbar)\n",
    "    saturation_mask = bags_hsv[:, :, 1] <115\n",
    "\n",
    "    mask = upper_mask * lower_mask * saturation_mask\n",
    "    red = bags[:, :, 0] * mask\n",
    "    green = bags[:, :, 1] * mask\n",
    "    blue = bags[:, :, 2] * mask\n",
    "    bags_masked = np.dstack((red, green, blue))\n",
    "    imgplot = plt.imshow(bags_masked)\n",
    "\n",
    "    plt.savefig('image' + str(i)+ '.png')\n",
    "    i+=1\n",
    "video.release()\n",
    "\n",
    "\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81059658",
   "metadata": {},
   "outputs": [],
   "source": [
    "#turn potentially non RGB frames into RGB for video stitching with av\n",
    "import av\n",
    "directory = r\"C:\\Users\\tzhou\"\n",
    "m = 0\n",
    "container = av.open(\"output.mp4\", \"w\")\n",
    "\n",
    "# Set the video format and frame rate\n",
    "video_stream = container.add_stream(\"vp9\", rate=30)\n",
    "video_stream.height = 500\n",
    "video_stream.width = 1500\n",
    "\n",
    "\n",
    "for file in os.listdir(directory):\n",
    "    for m in range(i):\n",
    "        if file == 'image' + str(m) + '.png':\n",
    "            # Open the image file\n",
    "            with Image.open(file) as image:\n",
    "                #image.show()\n",
    "                if image.mode != \"RGB\":\n",
    "                    image = image.convert(\"RGB\")\n",
    "                    image.save('image' + str(m) + '_rgb.png')\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57675615",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5360d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#user select background colors and they get subtracted out\n",
    "from PIL import Image\n",
    "\n",
    "# Define the threshold\n",
    "thresholdB = 255\n",
    "\n",
    "# Iterate through the pixels\n",
    "\n",
    "print(i)\n",
    "for m in range(i):\n",
    "    im = Image.open(\"image\" + str(m) + \"_rgb.png\")\n",
    "    pixels = im.load()\n",
    "    for x in range(im.width):\n",
    "        for y in range(im.height):\n",
    "            r, g, b = pixels[x, y]\n",
    "            # Check if the pixel is above the threshold\n",
    "            if b == thresholdB or g == 0:\n",
    "                # Change the pixel to white\n",
    "                pixels[x, y] = (0, 0, 0)\n",
    "\n",
    "    im.save(\"modified_image\" + str(m) + \".jpg\")\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3988c972",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d030d98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#100 PERCENT FUNCTIONAL VIDEO STITCHING ALGORITHM COMPLETED!!!!!!!!!!!!!!!\n",
    "\n",
    "frames = []\n",
    "for n in range(i):\n",
    "    frames.append(cv2.imread('modified_image' + str(n) + '.jpg'))\n",
    "\n",
    "# Set the frame width and height\n",
    "frame_width = frames[0].shape[1]\n",
    "frame_height = frames[0].shape[0]\n",
    "\n",
    "# Define the codec and create VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter('OutputNEW3.mp4', fourcc, 30.0, (frame_width,frame_height))\n",
    "\n",
    "# Write the frames to the video file\n",
    "for frame in frames:\n",
    "    out.write(frame)\n",
    "\n",
    "# Release the VideoWriter object\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c2a492",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ROI SELECTION\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "canvas = None\n",
    "drawing = False # true if mouse is pressed\n",
    "\n",
    "#Retrieve first frame\n",
    "def initialize_camera(cap):\n",
    "    _, frame = cap.read()\n",
    "    return frame\n",
    "\n",
    "\n",
    "# mouse callback function\n",
    "def mouse_draw_rect(event,x,y,flags, params):\n",
    "    global drawing, canvas\n",
    "\n",
    "    if drawing:\n",
    "        canvas = params[0].copy()\n",
    "\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        drawing = True\n",
    "        params.append((x,y)) #Save first point\n",
    "\n",
    "    elif event == cv2.EVENT_MOUSEMOVE:\n",
    "        if drawing:\n",
    "            cv2.rectangle(canvas, params[1],(x,y),(0,255,0),2)\n",
    "\n",
    "    elif event == cv2.EVENT_LBUTTONUP:\n",
    "        drawing = False\n",
    "        params.append((x,y)) #Save second point\n",
    "        cv2.rectangle(canvas,params[1],params[2],(0,255,0),2)\n",
    "\n",
    "\n",
    "def select_roi(frame):\n",
    "    global canvas\n",
    "    canvas = frame.copy()\n",
    "    params = [frame]\n",
    "    ROI_SELECTION_WINDOW = 'Select ROI'\n",
    "    cv2.namedWindow(ROI_SELECTION_WINDOW)\n",
    "    cv2.setMouseCallback(ROI_SELECTION_WINDOW, mouse_draw_rect, params)\n",
    "    roi_selected = False\n",
    "    while True:\n",
    "        cv2.imshow(ROI_SELECTION_WINDOW, canvas)\n",
    "        key = cv2.waitKey(10)\n",
    "\n",
    "        #Press Enter to break the loop\n",
    "        if key == 13:\n",
    "            break;\n",
    "\n",
    "\n",
    "    cv2.destroyWindow(ROI_SELECTION_WINDOW)\n",
    "    roi_selected = (3 == len(params))\n",
    "\n",
    "    if roi_selected:\n",
    "        p1 = params[1]\n",
    "        p2 = params[2]\n",
    "        if (p1[0] == p2[0]) and (p1[1] == p2[1]):\n",
    "            roi_selected = False\n",
    "\n",
    "    #Use whole frame if ROI has not been selected\n",
    "    if not roi_selected:\n",
    "        print('ROI Not Selected. Using Full Frame')\n",
    "        p1 = (0,0)\n",
    "        p2 = (frame.shape[1] - 1, frame.shape[0] -1)\n",
    "\n",
    "\n",
    "    return roi_selected, p1, p2\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    cap = cv2.VideoCapture(r\"C:\\Users\\tzhou\\OutputNEW1.mp4\")\n",
    "    #Grab first frame\n",
    "    first_frame = initialize_camera(cap)\n",
    "\n",
    "    #Select ROI for processing. Hit Enter after drawing the rectangle to finalize selection\n",
    "    roi_selected, point1, point2 = select_roi(first_frame)    \n",
    "\n",
    "    #Grab ROI of first frame\n",
    "    first_frame_roi = first_frame[point1[1]:point2[1], point1[0]:point2[0], :]\n",
    "    a = (point1[0]) #x upper left\n",
    "    b = (point1[1]) #y upper left\n",
    "    c = (point2[0]) #x lower right\n",
    "    d = (point2[1]) #y lower right\n",
    "\n",
    "    # Define the region to keep (x1, y1, x2, y2)\n",
    "    x1, y1, x2, y2 = (a, b, c, d)\n",
    "    t = 0\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        # Create black image with same dimensions as frame\n",
    "        black_image = np.zeros((frame.shape[0], frame.shape[1], 3), dtype=np.uint8)\n",
    "\n",
    "        # Copy region of interest from frame to black image\n",
    "        black_image[y1:y2, x1:x2] = frame[y1:y2, x1:x2]\n",
    "        image_bgr = cv2.cvtColor(black_image, cv2.COLOR_RGB2BGR)\n",
    "        cv2.imwrite(\"image\"+str(t)+\"ROI.jpg\", image_bgr)\n",
    "        t += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e808cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = []\n",
    "for n in range(t):\n",
    "    frames.append(cv2.imread('image' + str(n) + 'ROI.jpg'))\n",
    "    \n",
    "# Set the frame width and height\n",
    "frame_width = frames[0].shape[1]\n",
    "frame_height = frames[0].shape[0]\n",
    "\n",
    "    # Define the codec and create VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter('OutputNEW0.mp4', fourcc, 30.0, (frame_width,frame_height))\n",
    "\n",
    "    # Write the frames to the video file\n",
    "for frame in frames:\n",
    "    out.write(frame)\n",
    "\n",
    "    # Release the VideoWriter object\n",
    "out.release()\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247a71f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CLEAR IMAGES THAT WERE SAVED \n",
    "import os\n",
    "\n",
    "# List all the files in the current working directory\n",
    "files = os.listdir()\n",
    "\n",
    "# Loop through the files\n",
    "for file in files:\n",
    "    # Check if the file name contains the desired string\n",
    "    if \"image\" in file:\n",
    "        # Delete the file\n",
    "        os.remove(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebc499e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#COMPUTE FLOW STATISTIC\n",
    "import cv2\n",
    "\n",
    "# Create a VideoCapture object\n",
    "cap = cv2.VideoCapture(r\"C:\\Users\\tzhou\\OutputNEW0.mp4\")\n",
    "\n",
    "# Read the first frame of the video\n",
    "ret, prev_frame = cap.read()\n",
    "\n",
    "# Convert the frame to grayscale\n",
    "prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Define the parameters for the Farneback method\n",
    "params = dict(pyr_scale = 0.5, levels = 3, winsize = 15, iterations = 3, poly_n = 5, poly_sigma = 1.2, flags = 0)\n",
    "\n",
    "# Create an empty list to store the optical flow vectors\n",
    "flow = []\n",
    "\n",
    "# Read the frames of the video\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    # Exit the loop if there are no more frames\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert the frame to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Calculate the optical flow vectors\n",
    "    flow_vectors = cv2.calcOpticalFlowFarneback(prev_gray, gray, None, **params)\n",
    "\n",
    "    # Append the flow vectors to the list\n",
    "    flow.append(flow_vectors)\n",
    "\n",
    "    # Update the previous frame\n",
    "    prev_gray = gray\n",
    "\n",
    "# Release the VideoCapture object\n",
    "cap.release()\n",
    "\n",
    "# Calculate the rate of flow\n",
    "rate_of_flow = []\n",
    "for i in range(1, len(flow)):\n",
    "    rate_of_flow.append(np.mean(np.abs(flow[i] - flow[i-1])))\n",
    "average = np.mean(rate_of_flow)\n",
    "\n",
    "# Print the rate of flow\n",
    "print(average)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cfbc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create data\n",
    "time = range(1, len(flow))\n",
    "\n",
    "# Create a new figure and axes\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Plot the data\n",
    "ax.plot(time, rate_of_flow)\n",
    "\n",
    "# Add labels to the x- and y-axes\n",
    "ax.set_xlabel('Time (frame number)')\n",
    "ax.set_ylabel('Rate of Flow (pixels/frame)')\n",
    "\n",
    "# Add a title to the graph\n",
    "ax.set_title('Rate of Flow over Time')\n",
    "\n",
    "# Show the graph\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f633b230",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da56960e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1c124b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3740c05f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0e5d57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a12db50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dff67ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01426c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286aa35d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb40eb32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845ede39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fff55d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee978c78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9222f5a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d465f476",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
